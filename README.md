# NCBI-disease-corpus-named-entity-recognition

   Named entity recognition can be seen as a multi-text classification. It helps to identify key elements in a text like people, places, brands, companies, etc. in unstructured data with little effort. When humans read text, they try to recognize the keywords that are important to them. Humans cannot outperform if the data is a lot and this is the place where humans can solely rely on computers, but the computer does not know how to read. So, we need to help the computer to recognize the important entities. NLP studies the structure and rules of language and creates intelligent systems capable of deriving meaning from text and speech, while machine learning helps machines learn and improve over time. To learn what an entity is, a NER model needs to detect a word, a string of words that form an entity, and know which entity category it belongs to. In this course work, we have used the NCBI disease corpus which is a collection of 793 PubMed abstracts fully annotated at both mention and concept levels (in two files of train & test) and 6,892 disease mentions. We have implemented spacy, bidirectional LSTMs along with Glove for multi-classification and knowledge-based graphs. By using Spacy we can easily extract the parts of speech tags, positions and labels of the text category and we made two data frames, one is for parts of speech tags and the other is for text category labels which have 17 categorical values. We used the text category label data frame to predict multi-text classification. We have used both TF-IDF vectorizer and glove (6B.100d) word embeddings. We used the RNNs with Bi-LSTMs and then used the SoftMax for the output of 17 different classes and then trained the RNN model.
 
